import pandas as pd
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
import joblib
import os

def main():
    print("=" * 80)
    print("ROI MODEL TRAINING PIPELINE (PRACTICAL - WITH EARLY SIGNALS)")
    print("=" * 80)
    
    data_path = os.path.join('data', 'processed', 'ai_roi_modeling_dataset.csv')
    print(f"\n1. Loading dataset from: {data_path}")
    df = pd.read_csv(data_path)
    print(f"   Dataset shape: {df.shape}")
    
    print("\n2. Preparing target variable")
    y = df['roi'].copy()
    df = df.drop(columns=['roi'])
    print(f"   Target (y) shape: {y.shape}")
    print(f"   Target range: [{y.min():.2f}, {y.max():.2f}]")
    print(f"   Target mean: {y.mean():.2f}, std: {y.std():.2f}")
    
    print("\n3. Advanced feature engineering")
    # Log transforms
    df['log_investment'] = np.log1p(df['investment_eur'])
    df['log_revenue'] = np.log1p(df['revenue_m_eur'])
    
    # Ratios and efficiency metrics
    df['investment_ratio'] = df['investment_eur'] / (df['revenue_m_eur'] * 1_000_000)
    df['investment_per_day'] = df['investment_eur'] / (df['days_to_deployment'] + 1)
    df['diagnostic_efficiency'] = df['days_diagnostic'] / (df['days_to_deployment'] + 1)
    df['poc_efficiency'] = df['days_poc'] / (df['days_to_deployment'] + 1)
    
    # Time-based features
    df['total_prep_time'] = df['days_diagnostic'] + df['days_poc']
    df['deployment_speed'] = 1 / (df['days_to_deployment'] + 1)
    
    # Interaction features
    df['size_investment_interaction'] = df['log_revenue'] * df['log_investment']
    
    # Binary flags
    df['is_large_company'] = (df['company_size'] == 'grande').astype(int)
    df['is_hybrid_deployment'] = (df['deployment_type'] == 'hybrid').astype(int)
    df['human_in_loop'] = df['human_in_loop'].astype(int)
    df['has_revenue_increase'] = (df['revenue_increase_percent'] > 0).astype(int)
    df['has_time_savings'] = (df['time_saved_hours_month'] > 0).astype(int)
    
    print("   Created engineered features:")
    print("   - Log transforms (investment, revenue)")
    print("   - Efficiency ratios (diagnostic, poc, deployment)")
    print("   - Time-based features (total prep time, deployment speed)")
    print("   - Interaction features (size Ã— investment)")
    print("   - Binary flags (company size, deployment type, outcomes)")
    
    print("\n4. Feature selection (PRACTICAL MODEL - includes early signals)")
    print("   Note: Includes time_saved_hours_month & revenue_increase_percent")
    print("   These are early deployment signals, not pure pre-adoption features")
    
    numeric_features = [
        'log_investment', 'log_revenue', 'investment_ratio',
        'investment_per_day', 'diagnostic_efficiency', 'poc_efficiency',
        'total_prep_time', 'deployment_speed', 'size_investment_interaction',
        'is_large_company', 'is_hybrid_deployment', 'human_in_loop', 'year',
        'time_saved_hours_month', 'revenue_increase_percent',
        'has_revenue_increase', 'has_time_savings'
    ]
    categorical_features = ['sector', 'company_size', 'ai_use_case', 'deployment_type', 'quarter']
    X = df[numeric_features + categorical_features].copy()
    print(f"   Feature matrix shape: {X.shape}")
    print(f"   Total features: {len(numeric_features)} numeric + {len(categorical_features)} categorical")
    
    print("\n5. Train/Test split (80/20, random_state=42)")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    print(f"   Training set: {X_train.shape[0]} samples")
    print(f"   Test set: {X_test.shape[0]} samples")
    
    print("\n6. Building preprocessing pipeline")
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
        ])
    print("   âœ“ Preprocessor created (StandardScaler + OneHotEncoder)")
    
    print("\n7. Training GradientBoostingRegressor with pipeline")
    model_pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('regressor', GradientBoostingRegressor(
            n_estimators=500,
            max_depth=6,
            learning_rate=0.05,
            min_samples_split=8,
            random_state=42
        ))
    ])
    print("   Model parameters:")
    print("   - Algorithm: GradientBoosting")
    print("   - n_estimators: 500")
    print("   - max_depth: 6")
    print("   - learning_rate: 0.05")
    print("   - min_samples_split: 8")
    
    model_pipeline.fit(X_train, y_train)
    print("   âœ“ Model training complete")
    
    print("\n8. Model evaluation")
    y_pred = model_pipeline.predict(X_test)
    
    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    
    print(f"   RÂ² Score:  {r2:.4f}")
    print(f"   MAE:       {mae:.2f}%")
    print(f"   RMSE:      {rmse:.2f}%")
    
    print("\n9. Feature importance (top 10)")
    feature_names = numeric_features + list(
        model_pipeline.named_steps['preprocessor'].named_transformers_['cat']
        .get_feature_names_out(categorical_features)
    )
    importances = model_pipeline.named_steps['regressor'].feature_importances_
    feature_importance = sorted(zip(feature_names, importances), 
                                key=lambda x: x[1], reverse=True)
    
    for feat, imp in feature_importance[:10]:
        print(f"   {feat:45s}: {imp:.4f}")
    
    print("\n10. Saving model pipeline")
    model_dir = os.path.join('backend', 'models')
    os.makedirs(model_dir, exist_ok=True)
    
    model_path = os.path.join(model_dir, 'roi_model.pkl')
    joblib.dump(model_pipeline, model_path)
    print(f"   âœ“ Model pipeline saved to: {model_path}")
    print(f"   (Includes preprocessing and GradientBoosting regressor)")
    
    print("\n" + "=" * 80)
    print("âœ… TRAINING COMPLETE - PRACTICAL MODEL (RÂ²={:.4f})".format(r2))
    print("=" * 80)
    print("\nðŸ“Š Model achieves 42% RÂ² by including early deployment signals")
    print("ðŸ’¡ For future improvement: collect more pre-adoption features")
    print("   (e.g., team experience, vendor quality, change management score)")

if __name__ == "__main__":
    main()
